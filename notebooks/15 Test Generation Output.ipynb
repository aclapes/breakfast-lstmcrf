{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from ..src.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def import_labels(f):\n",
    "    ''' Read from a file all the labels from it '''\n",
    "    lines = f.readlines()\n",
    "    labels = []\n",
    "    i = 0\n",
    "    for l in lines:\n",
    "        t = l.split('\\t')\n",
    "        assert int(t[0]) == i\n",
    "        label = t[1].split('\\n')[0]\n",
    "        labels.append(label)\n",
    "        i += 1\n",
    "    return labels\n",
    "\n",
    "def to_categorical(y, nb_classes=None):\n",
    "    ''' Convert class vector (integers from 0 to nb_classes)\n",
    "    to binary class matrix, for use with categorical_crossentropy.\n",
    "    '''\n",
    "    if not nb_classes:\n",
    "        nb_classes = np.max(y)+1\n",
    "    Y = np.zeros((len(y), nb_classes))\n",
    "    for i in range(len(y)):\n",
    "        Y[i, y[i]] = 1.\n",
    "    return Y\n",
    "\n",
    "def generate_output(video_info, labels, length=16):\n",
    "    ''' Given the info of the vide, generate a vector of classes corresponding the output for each\n",
    "    clip of the video which features have been extracted.\n",
    "    '''\n",
    "    nb_frames = video_info['num_frames']\n",
    "    last_first_name = nb_frames - length + 1\n",
    "\n",
    "    start_frames = range(0, last_first_name, length)\n",
    "\n",
    "    # Check the output for each frame of the video\n",
    "    outputs = ['none'] * nb_frames\n",
    "    for i in range(nb_frames):\n",
    "        # Pass frame to temporal scale\n",
    "        t = i / float(nb_frames) * video_info['duration']\n",
    "        for annotation in video_info['annotations']:\n",
    "            if t >= annotation['segment'][0] and t <= annotation['segment'][1]:\n",
    "                outputs[i] = annotation['label']\n",
    "                label = annotation['label']\n",
    "                break\n",
    "\n",
    "    instances = []\n",
    "    for start_frame in start_frames:\n",
    "        # Obtain the label for this isntance and then its output\n",
    "        output = None\n",
    "\n",
    "        outs = outputs[start_frame:start_frame+length]\n",
    "        if outs.count(label) >= length / 2:\n",
    "            output = labels.index(label)\n",
    "        else:\n",
    "            output = 0\n",
    "        instances.append(output)\n",
    "\n",
    "    return instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open(\"../dataset/labels.txt\", \"r\") as f:\n",
    "    labels = import_labels(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subset': 'validation', 'num_frames': 4157, 'url': 'https://www.youtube.com/watch?v=Uw_0h2UrfyY', 'duration': 139.04, 'resolution': '426x240', 'annotations': [{'segment': [19.07183775351014, 117.91560686427458], 'label': 'Ballet'}]}\n"
     ]
    }
   ],
   "source": [
    "with open(\"../dataset/videos.json\", \"r\") as f:\n",
    "    videos_info = json.load(f)\n",
    "video_info = videos_info['Uw_0h2UrfyY']\n",
    "print(video_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 177, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "[[ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " [ 0.  0.  0. ...,  0.  0.  0.]\n",
      " ..., \n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]\n",
      " [ 1.  0.  0. ...,  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "instances = generate_output(video_info, labels, length=16)\n",
    "print(instances)\n",
    "Y = to_categorical(instances, nb_classes=200)\n",
    "print(Y[100:300])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Old test with old code implemented."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'subset': 'validation', 'resolution': '426x240', 'duration': 139.04, 'url': 'https://www.youtube.com/watch?v=Uw_0h2UrfyY', 'annotations': [{'segment': [19.07183775351014, 117.91560686427458], 'label': 'Ballet'}], 'num_frames': 4157}\n"
     ]
    }
   ],
   "source": [
    "video = None\n",
    "for v in dataset.get_subset_videos('validation'):\n",
    "    if v.video_id == 'Uw_0h2UrfyY':\n",
    "        video = v\n",
    "print(video.serialize())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      " 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177\n",
      " 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177\n",
      " 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177\n",
      " 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177\n",
      " 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177\n",
      " 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177\n",
      " 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177\n",
      " 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177\n",
      " 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177\n",
      " 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177 177\n",
      " 177 177 177 177   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0]\n"
     ]
    }
   ],
   "source": [
    "video.get_video_instances(16, 0)\n",
    "ground_trouth = np.array([instance.output for instance in video.instances])\n",
    "print(ground_trouth)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0 105 105 105 105 105   0   0   0   0   0   0   0   0 105 105 105 105\n",
      " 105 105 105 105 105 105 105 105 105   0   0 105 105 105 105 105 105 105\n",
      " 105 105 105 105 105 105 105 105 105 105 105 105 105 105 105 105 105 105\n",
      " 105 105 105 105   0 105 105   0 105   0   0   0   0   0   0   0   0   0\n",
      "   0 177 177 177   0   0 177   0   0 177 177 177 177 177 177 177 177 177\n",
      " 177 177 177 177 177 177 177   0   0   0   0 177   0 177 177 177 177 177\n",
      " 177 177 177 177 177 177 177 177 177 177   0 177   0   0 177 177 177 177\n",
      " 177 177 177 177 177   0   0 177 177 105 105 177 177 105 105 105 105 177\n",
      " 177 177 105 177 177 177 177 177 177 177 177 177 177 177 177 105 105 105\n",
      " 105 105 105   0   0 105   0 177 177 177 177 177   0 177 177 177 177 177\n",
      " 177 177 177 105 105 105 105 105 105 105 105 105 105 105 105 105 105 105\n",
      " 105 105   0   0   0 105 105 105 105 105 105   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0 105 177 177 177 105   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0]\n",
      "[1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "detection_prediction_path = detection_predictions_path + video.video_id + '.npy'\n",
    "classification_prediction_path =  classification_predictions_path + video.video_id + '.npy'\n",
    "\n",
    "class_prediction = np.load(classification_prediction_path)\n",
    "detection_prediction = np.load(detection_prediction_path)\n",
    "\n",
    "print(class_prediction)\n",
    "print(detection_prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "   0 105 105 105 105 105   0   0   0   0   0   0   0   0 105 105 105 105\n",
      " 105 105 105 105 105 105 105 105 105   0   0 105 105 105 105 105 105 105\n",
      " 105 105 105 105 105 105 105 105 105 105 105 105 105 105 105 105 105 105\n",
      " 105 105 105 105   0 105 105   0 105   0   0   0   0   0   0   0   0   0\n",
      "   0 177 177 177   0   0 177   0   0 177 177 177 177 177 177 177 177 177\n",
      " 177 177 177 177 177 177 177   0   0   0   0 177   0 177 177 177 177 177\n",
      " 177 177 177 177 177 177 177 177 177 177   0 177   0   0 177 177 177 177\n",
      " 177 177 177 177 177   0   0 177 177 105 105 177 177 105 105 105 105 177\n",
      " 177 177 105 177 177 177 177 177 177 177 177 177 177 177 177 105 105 105\n",
      " 105 105 105   0   0 105   0 177 177 177 177 177   0 177 177 177 177 177\n",
      " 177 177 177 105 105 105 105 105 105 105 105 105 105 105 105 105 105 105\n",
      " 105 105   0   0   0 105 105 105 105 105 105   0   0   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0   0 105 177 177 177 105   0   0   0   0   0\n",
      "   0   0   0   0   0   0   0]\n",
      "[{'label': 105,\n",
      "  'scores': 1.0,\n",
      "  'segment': [10.167948039451527, 12.843723839307192]},\n",
      " {'label': 105,\n",
      "  'scores': 1.0,\n",
      "  'segment': [17.124965119076254, 24.081982198700985]},\n",
      " {'label': 105,\n",
      "  'scores': 1.0,\n",
      "  'segment': [25.15229251864325, 40.67179215780611]},\n",
      " {'label': 105,\n",
      "  'scores': 1.0,\n",
      "  'segment': [41.20694731777724, 42.27725763771951]},\n",
      " {'label': 105,\n",
      "  'scores': 1.0,\n",
      "  'segment': [42.81241279769064, 43.347567957661774]},\n",
      " {'label': 177, 'scores': 1.0, 'segment': [48.6991195573731, 50.3045850372865]},\n",
      " {'label': 177,\n",
      "  'scores': 1.0,\n",
      "  'segment': [51.374895357228766, 51.9100505171999]},\n",
      " {'label': 177,\n",
      "  'scores': 1.0,\n",
      "  'segment': [52.980360837142165, 61.5428433966803]},\n",
      " {'label': 177,\n",
      "  'scores': 1.0,\n",
      "  'segment': [63.68346403656483, 64.21861919653595]},\n",
      " {'label': 177, 'scores': 1.0, 'segment': [64.7537743565071, 72.7811017560741]},\n",
      " {'label': 177,\n",
      "  'scores': 1.0,\n",
      "  'segment': [73.31625691604522, 73.85141207601636]},\n",
      " {'label': 177,\n",
      "  'scores': 1.0,\n",
      "  'segment': [74.92172239595862, 79.73811883569881]},\n",
      " {'label': 177,\n",
      "  'scores': 0.59375,\n",
      "  'segment': [80.80842915564108, 97.93339427471734]},\n",
      " {'label': 105,\n",
      "  'scores': 0.40625,\n",
      "  'segment': [80.80842915564108, 97.93339427471734]},\n",
      " {'label': 105,\n",
      "  'scores': 1.0,\n",
      "  'segment': [99.00370459465961, 99.53885975463074]},\n",
      " {'label': 177,\n",
      "  'scores': 1.0,\n",
      "  'segment': [100.07401491460188, 102.74979071445753]},\n",
      " {'label': 105,\n",
      "  'scores': 0.68000000000000005,\n",
      "  'segment': [103.28494587442867, 116.66382487370699]},\n",
      " {'label': 177,\n",
      "  'scores': 0.32000000000000001,\n",
      "  'segment': [103.28494587442867, 116.66382487370699]},\n",
      " {'label': 105,\n",
      "  'scores': 1.0,\n",
      "  'segment': [118.26929035362039, 121.48022131344719]},\n",
      " {'label': 177,\n",
      "  'scores': 0.59999999999999998,\n",
      "  'segment': [129.5075487130142, 132.18332451286986]},\n",
      " {'label': 105,\n",
      "  'scores': 0.40000000000000002,\n",
      "  'segment': [129.5075487130142, 132.18332451286986]}]\n"
     ]
    }
   ],
   "source": [
    "mix = np.zeros(class_prediction.shape, dtype=np.int64)\n",
    "for pos in range(class_prediction.size):\n",
    "    if detection_prediction[pos] == 1:\n",
    "        mix[pos] = class_prediction[pos]\n",
    "\n",
    "print(mix)\n",
    "\n",
    "prediction = get_temporal_predictions_2(mix, fps=video.fps)\n",
    "pprint.pprint(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
