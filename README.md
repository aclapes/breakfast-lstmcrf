# Temporal segmentation on breakfast dataset

## Instructions

0. Clone the repository (or download) and navigate where the code and Dockerfile are placed.

1. Build the docker image:
```bash
docker build -t aclapes/breakfast:latest .
```

2. Run a docker container from aclapes/breakfast image:
```bash
nvidia-docker run -it -v /data/data2/aclapes/Datasets/:/data/datasets/ aclapes/breakfast:latest
```
Option ```-v``` allows mapping a directory from docker's host into a running docker container.

3. Navigate to the python source code.
```bash
cd /home/dockeruser/src/
```

4. To run the code you need to run the python script ```lstmcrf.py```. Let see the options this script provides:
```bash
python lstmcrf.py -h
usage: lstmcrf.py [-h] [-i INPUT_FILE] [-b BATCH_SIZE] [-lr LEARN_RATE]
                  [-e NUM_EPOCHS] [-ot OPTIMIZER_TYPE] [-M MODEL_TYPE]
                  [-s HIDDEN_SIZE] [-p DROP_PROB]

Perform labelling of sequences using a LSTMCRF model.

optional arguments:
  -h, --help            show this help message and exit
  -i INPUT_FILE, --input-file INPUT_FILE
                        Dataset in hdf5 format (default:
                        /data/datasets/breakfast/fv/s1/dataset.8-20.h5)
  -b BATCH_SIZE, --batch-size BATCH_SIZE
                        Batch size (default: 32)
  -lr LEARN_RATE, --learning-rate LEARN_RATE
                        Learning rate (default: 0.0001)
  -e NUM_EPOCHS, --num_epochs NUM_EPOCHS
                        Num epochs (default: 2000)
  -ot OPTIMIZER_TYPE, --optimizer-type OPTIMIZER_TYPE
                        Optimizer type (sgd or adam) (default: adam)
  -M MODEL_TYPE, --model-type MODEL_TYPE
                        Model type (crf, lstm or lstmcrf) (default: lstmcrf)
  -s HIDDEN_SIZE, --hidden-size HIDDEN_SIZE
                        Hidden size (default: 512)
  -p DROP_PROB, --drop-prob DROP_PROB
                        Dropout probability (default: 0.5)
```

5. Let assume we want to run the LSTMCRF pipeline. This is an example of invocation:
```bash
CUDA_VISIBLE_DEVICES="0" python -u lstmcrf.py -M lstmcrf -i /data/datasets/breakfast/fv/s1/dataset.h5 -b 32 -lr 0.001 -e 1000
```
This instruction trains, validates, and tests a LSTMCRF model (specified by ```-M```). The ```dataset```, passed via
 ```-i```,  is expected to be a hdf5 type file with a certain format. ```create_fv_breakfast_dataset.py``` provides
  a way to do it (see "Additional instructions" below). 

You can pass multiple GPUs through ```CUDA_VISIBLE_DEVICES``` (e.g. "0,2,5"). However, the code is not multi-GPU, 
so you need to choose one particular device, e.g. 0-th.

(Note: You can ignore python's -u option, related to the buffering of the stdout).

## Additional instructions

To run the code in ```lstmcrf.py```, you need to construct first a dataset containing the features with a certain format. 
To do this, we provide create_X_breakfast_dataset python scripts in ```dataset``` directory. 

This is an example of how to use ```create_fv_breakfast_dataset.py```:

```bash
cd ./dataset/
python -u create_fv_breakfast_dataset.py -d /data/datasets/breakfast/fv/s1/ -i videos.json -l labels.txt 
-o /data/datasets/breakfast/fv/s1/test.h5
```

Details:
```-d``` specifies the directory of the breakfast fisher vector features in txt files, as provided by the authors in: 
http://serre-lab.clps.brown.edu/resource/breakfast-actions-dataset/ (Frame-based precomputed reduced FV (64 dim)).
```-i``` expects a json containing segmentation annotations and other metadata.
```-l``` expects a text file containing the numbering of the classes. In our scenario, we use the 48 breakfast subactions.

Both ```videos.json``` and ```labels.txt``` are already provided in this repository. They were one-time generated by
 ```breakfast_config.py``` (also provided). This is a convenient format already used in other people code's 
 (https://github.com/imatge-upc/activitynet-2016-cvprw) to which we can be comparing in the future.

