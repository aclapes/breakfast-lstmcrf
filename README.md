# Temporal segmentation on breakfast dataset

## Instructions

1. Pull the docker from dockerhub.
```bash
docker pull aclapes/breakfast
``

2. Run the docker: `
```bash
nvidia-docker run -it -v /data/data2/aclapes/Datasets/:/data/datasets aclapes/breakfast
```

3. Navigate to the python source code.
```bash
cd /home/dockeruser/src/breakfast-lstmcrf
```

4. To run the code you need to run the python script lstmcrf.py. Let see the options this script provides:
```bash
python lstmcrf.py -h
usage: lstmcrf.py [-h] [-i INPUT_FILE] [-b BATCH_SIZE] [-lr LEARN_RATE]
                  [-e NUM_EPOCHS] [-ot OPTIMIZER_TYPE] [-M MODEL_TYPE]
                  [-s HIDDEN_SIZE] [-p DROP_PROB]

Perform labelling of sequences using a LSTMCRF model.

optional arguments:
  -h, --help            show this help message and exit
  -i INPUT_FILE, --input-file INPUT_FILE
                        Dataset in hdf5 format (default:
                        /data/datasets/breakfast/fv/s1/dataset.8-20.h5)
  -b BATCH_SIZE, --batch-size BATCH_SIZE
                        Batch size (default: 32)
  -lr LEARN_RATE, --learning-rate LEARN_RATE
                        Learning rate (default: 0.0001)
  -e NUM_EPOCHS, --num_epochs NUM_EPOCHS
                        Num epochs (default: 2000)
  -ot OPTIMIZER_TYPE, --optimizer-type OPTIMIZER_TYPE
                        Optimizer type (sgd or adam) (default: adam)
  -M MODEL_TYPE, --model-type MODEL_TYPE
                        Model type (crf, lstm or lstmcrf) (default: lstmcrf)
  -s HIDDEN_SIZE, --hidden-size HIDDEN_SIZE
                        Hidden size (default: 512)
  -p DROP_PROB, --drop-prob DROP_PROB
                        Dropout probability (default: 0.5)
```

5. Let assume we want to run the LSTMCRF pipeline. This is an example of invocation:
```bash
CUDA_VISIBLE_DEVICES="0" python -u lstmcrf.py -M lstmcrf -i /data/datasets/breakfast/fv/s1/dataset.h5 -b 32 -lr 0.001 -e 1000
```
This instruction is going to train, validate, and test a LSTMCRF model. The dataset (-i) has to be constructed
using create_fv_breakfast_dataset.py for instance. 

You can pass multiple GPUs through CUDA_VISIBLE_DEVICES (e.g. "0,2,5"). However, the code is not multi-GPU, 
so we choose the 0-th GPU to run the code.

(Note: You can ignore python's -u option, related to the buffering of the stdout).

## Additional instructions

To run the code in lstmcrf.py, you need to construct first a dataset in a certain format. To do this, we provide
create_X_breakfast_dataset.py files. This is an example of how to use the "fv one:

```bash
python -u create_fv_breakfast_dataset.py -d /datasets/breakfast/fv/s1/ -i dataset/videos.json -l dataset/labels.txt 
-o /datasets/breakfast/fv/s1/test.h5
```

videos.json and labels.txt contain respectively the annotations and the list of classes for the breakfast dataset
segmentation problem. They are one-time generated by breakfast_config.py. This is a convenient format to use
other people code's (https://github.com/imatge-upc/activitynet-2016-cvprw).

